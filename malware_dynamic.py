import time
import joblib
import pandas as pd

# Load the trained dynamic malware model using joblib
model = joblib.load("models/malware_dynamic_model.pkl")

def simulate_dynamic_behavior(path):
    """
    Simulates dynamic behavior signals for a file.
    """
    fake_indicators = {
        "file_ops": 3,   # created/modified files
        "reg_ops": 1,    # registry-like ops
        "net_ops": 2,    # attempted connections
        "proc_injections": 0
    }
    time.sleep(0.5)
    score = 0.0
    score += 0.25 if fake_indicators["net_ops"] >= 2 else 0.1 if fake_indicators["net_ops"] >= 1 else 0
    score += 0.25 if fake_indicators["file_ops"] >= 3 else 0.1 if fake_indicators["file_ops"] >= 1 else 0
    score += 0.2 if fake_indicators["reg_ops"] >= 1 else 0
    score += 0.2 if fake_indicators["proc_injections"] >= 1 else 0
    return min(score, 1.0), fake_indicators

def heuristic_score(path):
    """Calculate heuristic score and return indicators."""
    score, indicators = simulate_dynamic_behavior(path)
    return score, indicators

def ai_classification(path):
    """Run AI model on extracted dynamic features."""
    _, indicators = heuristic_score(path)
    df = pd.DataFrame([{
        "file_ops": indicators["file_ops"],
        "reg_ops": indicators["reg_ops"],
        "net_ops": indicators["net_ops"],
        "proc_injections": indicators["proc_injections"]
    }])
    prediction = model.predict(df)[0]

    # Handle case where model was trained on only one class
    proba = model.predict_proba(df)[0]
    if len(proba) == 1:
        probability = proba[0]  # always 1.0
    else:
        probability = proba[1]  # probability of "malicious" class

    return prediction, probability

def detect_dynamic_malware(path, threshold=0.7):
    """Unified detection: heuristic + AI model."""
    heuristic, indicators = heuristic_score(path)
    prediction, prob = ai_classification(path)
    print(f"[Hackslayer] Heuristic score: {heuristic:.2f}, AI probability: {prob:.2f}")
    if prob > threshold or heuristic > 0.6:
        return "Malicious", {"heuristic": heuristic, "ai_prob": prob, **indicators}
    else:
        return "Clean", {"heuristic": heuristic, "ai_prob": prob, **indicators}
